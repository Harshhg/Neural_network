{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutionary_neural_network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6osVuT5UWa3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a9de227-3e05-4401-9018-875c69b4ef7e"
      },
      "source": [
        "# Importing all the modules required for CNN creation\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIEXq3YbXfDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolution model\n",
        "from keras.layers import Convolution2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiLHB_WKXjdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Max Pooling\n",
        "from keras.layers import MaxPool2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdeopeB-YNV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flattening \n",
        "from keras.layers import Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE9MQOGkYRka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing ANN model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jdS7SVHYhSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "54fca9b4-7c6c-4260-a5c6-4d7842b8f63d"
      },
      "source": [
        "# Classifier model\n",
        "model = Sequential()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0709 10:58:38.466949 140455074166656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOmxFshWYysO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "da56114f-b7b9-4a08-aa9a-9588db9231e6"
      },
      "source": [
        "# Creating a convolution layer under model namespace\n",
        "\n",
        "model.add(Convolution2D(64,3,3,activation='relu', input_shape=(128,128,3)))  # 64 features for a image in a single shot.. that is extracting 128 features for an object.. (cpu dependent) | 3,3 - sub image we are taking | activation function\n",
        "\n",
        "# input shape :- image dimension--- minimum size of the images.. and 3-color image, 1-grayscale image          \n",
        "# When outcomes will be generated that will lead to feature maps.\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", input_shape=(128, 128,...)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxE_okWJZPHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b8ef1d01-01d2-43d2-b1ab-e351f6b9daee"
      },
      "source": [
        "# Now we can apply max pooling in feature maps\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "# Pool size should be smaller than image dimension in above code..(2,2  or 3,3)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0709 11:19:55.381544 140455074166656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpEomMVOdqdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here output will be a sub object\n",
        "# then we can apply flattening\n",
        "model.add(Flatten())  # We don't have to supply any parameter because ti will convert dataset into columns so that we can use this as input of ANN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO5CWtCCeXzh",
        "colab_type": "text"
      },
      "source": [
        "# Now we can add flatten output to input as Aritficial Neural Network - First Hidden layer/input layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPRKR8mzd7CM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(128,activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nghSOGCeVnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output layer ..\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xuzuAbckECH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "# Code for reading images dataset from directory\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'data/train',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'data/validation',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=2000,\n",
        "        epochs=50,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=800)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLuv823ek_iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
